{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standing-membership",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "democratic-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import re\n",
    "import math\n",
    "import statistics #stdev\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "experimental-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-million",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "objective-minnesota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42260</th>\n",
       "      <td>Hargh... this film is so bad it's almost good. Trash at its best. Jesus' bro vs. pimps...come on. I'd say that you'd actually have to see this, it's so bad... my sides hurt when I laughed. I can't understand why this isn't in the worst 100.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 review  \\\n",
       "42260  Hargh... this film is so bad it's almost good. Trash at its best. Jesus' bro vs. pimps...come on. I'd say that you'd actually have to see this, it's so bad... my sides hurt when I laughed. I can't understand why this isn't in the worst 100.   \n",
       "\n",
       "       label  \n",
       "42260      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/achraf/Desktop/codes et commandes/git_wwsssuuup/IMDB Dataset.csv')\n",
    "df = df.drop_duplicates()\n",
    "df.rename(columns={'sentiment' : 'label'}, inplace = True) # rename column\n",
    "df = df.replace({'negative': 1, 'positive': 0})\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da930400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000) # Take a subset for faster code test\n",
    "test = df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d5d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df['review'])\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-millennium",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "experienced-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du tokenizer\n",
    "def tokenizer(review):\n",
    "    liste_tokens = [] #liste de tokens à retourne\n",
    "    tokens = re.split('[/ : _ . -]', review) # split de l'review et stockage dans liste intérmédiaire\n",
    "    for i in tokens: # boucler sur les tokens pour supprimer les vides\n",
    "        if i != '':\n",
    "            liste_tokens.append(i) # il faut mettre dans la nouvelle liste pour être sur que l'élément n'y est pas\n",
    "    return liste_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "confident-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_crafting(df):\n",
    "    '''\n",
    "    Each function is preceded by a comment explaining its aim. Between each two different functions line jumps (breaks).\n",
    "    '''    \n",
    "    for i, row in df.iterrows():\n",
    "        # Calculate average word length\n",
    "        words = list(filter(None, re.split(r\"\\d*\\W+\", row['review'])))\n",
    "        df.loc[i, 'avg_word_length'] = sum(len(word) for word in words) / len(words)\n",
    "        \n",
    "        #Letter Count\n",
    "        df.loc[i, 'letter_count'] = sum(c.isalpha() for c in row['review'])\n",
    "        \n",
    "        # number of special characters\n",
    "        df.loc[i, 'special_characters_number'] = len(re.sub('[A-Za-z0-9\\s]+', '', row['review']\n",
    "                                                            .replace('/', '').replace('.', '')))\n",
    "        \n",
    "        # Compute entropy\n",
    "        prob = [float(row['review'].count(c)) / len(row['review']) for c in dict.fromkeys(list(row['review']))]\n",
    "        df.loc[i, 'entropy'] = sum([(p * math.log(p) / math.log(2.0)) for p in prob])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_review(df):\n",
    "    return df['review']\n",
    "\n",
    "def get_numerical_features(df):\n",
    "    return df[['avg_word_length', 'letter_count', 'special_characters_number', 'entropy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2f52e",
   "metadata": {},
   "source": [
    "## Transformers & pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3433cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "craft_features = FunctionTransformer(feature_crafting, validate=False)\n",
    "get_text_data = FunctionTransformer(get_review, validate=False)\n",
    "get_numeric_data = FunctionTransformer(get_numerical_features, validate=False)\n",
    "# Pipelines\n",
    "numeric_pipeline = Pipeline([('selector', get_numeric_data)])\n",
    "text_pipeline = Pipeline([('selector', get_text_data), ('vectorizer', CountVectorizer(tokenizer = tokenizer, \n",
    "                                                                                      lowercase = False, \n",
    "                                                                                      max_df = 1.0,\n",
    "                                                                                      ngram_range = (1, 2)))])\n",
    "\n",
    "featureunionvect = FeatureUnion([('numeric', numeric_pipeline), ('text', text_pipeline)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-minimum",
   "metadata": {},
   "source": [
    "## Pipeline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd2bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline([('numerical_features', craft_features),\n",
    "                        ('vect', featureunionvect),\n",
    "                        ('lr', LogisticRegression(max_iter = 7600, random_state=26, solver='lbfgs'))\n",
    "                       ])\n",
    "\n",
    "lr_pipe = lr_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-finland",
   "metadata": {},
   "source": [
    "## Pipe Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "conventional-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline = Pipeline([('vect', featureunionvect),\n",
    "                         ('clf', xgb.XGBClassifier(learning_rate=0.1))])\n",
    "\n",
    "xgb_pipe = xgb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "signed-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>entropy</th>\n",
       "      <th>letter_count</th>\n",
       "      <th>lr_proba_negative</th>\n",
       "      <th>lr_proba_positive</th>\n",
       "      <th>special_characters_number</th>\n",
       "      <th>xgb_proba_negative</th>\n",
       "      <th>xgb_proba_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46452</th>\n",
       "      <td>4.179842</td>\n",
       "      <td>-4.459055</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>0.999470</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.395418</td>\n",
       "      <td>0.604582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31128</th>\n",
       "      <td>4.234818</td>\n",
       "      <td>-4.458602</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.927792</td>\n",
       "      <td>0.072208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_word_length   entropy  letter_count  lr_proba_negative  \\\n",
       "46452         4.179842 -4.459055        2115.0           0.999470   \n",
       "31128         4.234818 -4.458602        1046.0           0.999788   \n",
       "\n",
       "       lr_proba_positive  special_characters_number  xgb_proba_negative  \\\n",
       "46452           0.000530                       85.0            0.395418   \n",
       "31128           0.000212                       38.0            0.927792   \n",
       "\n",
       "       xgb_proba_positive  \n",
       "46452            0.604582  \n",
       "31128            0.072208  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_test\n",
    "\n",
    "lr_proba = lr_pipe.predict_proba(test)\n",
    "xgb_proba = xgb_pipe.predict_proba(test)\n",
    "\n",
    "test['xgb_proba_positive'] = [item[0] for item in xgb_proba]\n",
    "test['xgb_proba_negative'] = [item[1] for item in xgb_proba]\n",
    "\n",
    "test['lr_proba_positive'] = [item[0] for item in lr_proba]\n",
    "test['lr_proba_negative'] = [item[1] for item in lr_proba]\n",
    "\n",
    "test[test.columns.difference(['review'])].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e2a7f",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sunrise-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to SAVE-LOAD using pickle #\n",
    "import pickle\n",
    "\n",
    "# save\n",
    "with open('model_pipeline_060621.pkl','wb') as f:\n",
    "    pickle.dump(lr_pipe, f)\n",
    "\n",
    "# load\n",
    "with open('model_pipeline_060621.pkl', 'rb') as f:\n",
    "    clf_pipe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38974cac",
   "metadata": {},
   "source": [
    "#### Test predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "color-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>entropy</th>\n",
       "      <th>letter_count</th>\n",
       "      <th>lr_proba_negative</th>\n",
       "      <th>lr_proba_positive</th>\n",
       "      <th>special_characters_number</th>\n",
       "      <th>xgb_proba_negative</th>\n",
       "      <th>xgb_proba_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46452</th>\n",
       "      <td>4.179842</td>\n",
       "      <td>-4.459055</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>0.999470</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.395418</td>\n",
       "      <td>0.604582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31128</th>\n",
       "      <td>4.234818</td>\n",
       "      <td>-4.458602</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.927792</td>\n",
       "      <td>0.072208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_word_length   entropy  letter_count  lr_proba_negative  \\\n",
       "46452         4.179842 -4.459055        2115.0           0.999470   \n",
       "31128         4.234818 -4.458602        1046.0           0.999788   \n",
       "\n",
       "       lr_proba_positive  special_characters_number  xgb_proba_negative  \\\n",
       "46452           0.000530                       85.0            0.395418   \n",
       "31128           0.000212                       38.0            0.927792   \n",
       "\n",
       "       xgb_proba_positive  \n",
       "46452            0.604582  \n",
       "31128            0.072208  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_proba = clf_pipe.predict_proba(test)\n",
    "\n",
    "test['lr_proba_positive'] = [item[0] for item in lr_proba]\n",
    "test['lr_proba_negative'] = [item[1] for item in lr_proba]\n",
    "\n",
    "test[test.columns.difference(['review'])].head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
