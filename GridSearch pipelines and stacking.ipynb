{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fifteen-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import math\n",
    "import statistics #stdev\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 130)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.width\", 300)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-location",
   "metadata": {},
   "source": [
    "### <font color = darkblue>${\\textbf{Dataset}}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "heard-reunion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28734</th>\n",
       "      <td>it's been awhile since i've seen Cold Mountain,bit i do knew that i enjoyed it immensely.though it does take place during the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                  review  label\n",
       "28734  it's been awhile since i've seen Cold Mountain,bit i do knew that i enjoyed it immensely.though it does take place during the ...      0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/ahamid/git_wwsssuuup/IMDB Dataset.csv')\n",
    "df = df.drop_duplicates()\n",
    "df.rename(columns={'sentiment' : 'label'}, inplace = True) # rename column\n",
    "df = df.sample(10000) # Take a subset for faster code test\n",
    "df = df.replace({'negative': 1, 'positive': 0})\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3dc43f",
   "metadata": {},
   "source": [
    "### <font color = darkblue>${\\textbf{Preprocessing}}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "191fb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Digit Count\n",
    "def digit_count(review):\n",
    "    count=0\n",
    "    for c in review:\n",
    "        if c.isnumeric():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "#Letter Count\n",
    "def letter_count(review):\n",
    "    count=0\n",
    "    for c in review:\n",
    "        if c.isalpha(): # The isalpha() method returns True if all the characters are alphabet letters (a-z).\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Check special charcters\n",
    "'''Non exhaustive list'''\n",
    "def checkSpecial(string): \n",
    "    regex = re.compile('[-@_!#$%^&*()<>?|}{~]') \n",
    "    i=0\n",
    "    for char in string:   \n",
    "        if regex.search(char):\n",
    "            i+=1\n",
    "    return i\n",
    "\n",
    "\n",
    "# Compute entropy\n",
    "def entropy(review):\n",
    "        string = review.strip()\n",
    "        prob = [float(string.count(c)) / len(string) for c in dict.fromkeys(list(string))]\n",
    "        entropy = sum([(p * math.log(p) / math.log(2.0)) for p in prob])\n",
    "        return entropy\n",
    "\n",
    "\n",
    "# Average word length\n",
    "def avg_word_length(review):\n",
    "    words = list(filter(None, re.split(r\"\\d*\\W+\", review)))\n",
    "    average = sum(len(word) for word in words) / len(words)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41c8679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform(df):\n",
    "    switch = {'words_avg' : avg_word_length, 'digits_count' : digit_count, 'letter_count' : letter_count,\n",
    "              'specialChar' : checkSpecial, 'entropy' : entropy}\n",
    "    for key in switch:\n",
    "        df.insert(1, key, [switch[key](review) for review in df['review']])\n",
    "\n",
    "# Transform Dataset(feature_transform): add computed features\n",
    "feature_transform(df)\n",
    "\n",
    "df['num.'] = df['review'].apply(lambda i: i.count('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de2ddbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['review'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d40363",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b81b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[df.columns.difference(['label'])],  \n",
    "                                                    df[\"label\"], test_size = 0.1, random_state = 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-relative",
   "metadata": {},
   "source": [
    "### <font color = darkblue>${\\textbf{1. multiple GridSearches loop on multiple pipelines}}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f402b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('lr', LogisticRegression(random_state = 26))])\n",
    "\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "pipe_nb = Pipeline([('minmax', MinMaxScaler()),\n",
    "                    ('clf', mnb)])\n",
    "\n",
    "\n",
    "pipe_nb_pca = Pipeline([('pca', PCA(n_components = 'mle', svd_solver = 'full')), \n",
    "                        ('minmax', MinMaxScaler()),\n",
    "                        ('clf', mnb)])\n",
    "\n",
    "pipe_nb_scl = Pipeline([('scl', StandardScaler()), \n",
    "                        ('minmax', MinMaxScaler()),                      \n",
    "                        ('clf', mnb)])\n",
    "\n",
    "\n",
    "pipe_nb_scl_pca = Pipeline([('scl', StandardScaler()),\n",
    "                            ('pca', PCA(n_components = 'mle', svd_solver = 'full')), \n",
    "                            ('minmax', MinMaxScaler()),\n",
    "                            ('clf', mnb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "296df166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid search params\n",
    "param_range = [9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_lr = [{'lr__penalty': ['l1', 'l2'],\n",
    "                   'lr__C': param_range_fl,\n",
    "                   'lr__solver': ['liblinear']}] \n",
    "\n",
    "grid_params_nb = [{'clf__alpha': [0.0, 1.0],\n",
    "                   'clf__fit_prior': ['True', 'False']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0df59187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator = pipe_lr, param_grid = grid_params_lr, scoring='accuracy', n_jobs=jobs)\n",
    "gs_nb = GridSearchCV(estimator = pipe_nb, param_grid = grid_params_nb, scoring='accuracy', n_jobs=jobs)\n",
    "gs_nb_pca = GridSearchCV(estimator = pipe_nb_pca, param_grid = grid_params_nb, scoring='accuracy', n_jobs=jobs)\n",
    "gs_nb_scl = GridSearchCV(estimator = pipe_nb_scl, param_grid = grid_params_nb, scoring='accuracy', n_jobs=jobs)\n",
    "gs_nb_scl_pca = GridSearchCV(estimator = pipe_nb_scl_pca, param_grid = grid_params_nb, scoring='accuracy', n_jobs=jobs)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_nb, gs_nb_pca, gs_nb_scl, gs_nb_scl_pca]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic regression', 1: 'Naive Bayes', 2: 'Naive Bayes PCA', 3: 'Naive Bayes SCL', 4: 'Naive Bayes PCA SCL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e6a0758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic regression\n",
      "Best params: {'lr__C': 1.0, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}\n",
      "Best training accuracy: 0.546\n",
      "Test set accuracy score for best params: 0.551 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Best params: {'clf__alpha': 0.0, 'clf__fit_prior': 'True'}\n",
      "Best training accuracy: 0.508\n",
      "Test set accuracy score for best params: 0.536 \n",
      "\n",
      "Estimator: Naive Bayes PCA\n",
      "Best params: {'clf__alpha': 0.0, 'clf__fit_prior': 'True'}\n",
      "Best training accuracy: 0.504\n",
      "Test set accuracy score for best params: 0.508 \n",
      "\n",
      "Estimator: Naive Bayes SCL\n",
      "Best params: {'clf__alpha': 0.0, 'clf__fit_prior': 'True'}\n",
      "Best training accuracy: 0.508\n",
      "Test set accuracy score for best params: 0.536 \n",
      "\n",
      "Estimator: Naive Bayes PCA SCL\n",
      "Best params: {'clf__alpha': 1.0, 'clf__fit_prior': 'True'}\n",
      "Best training accuracy: 0.505\n",
      "Test set accuracy score for best params: 0.507 \n",
      "\n",
      "Classifier with best test set accuracy: Logistic regression\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "        # Fit grid search\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-operations",
   "metadata": {},
   "source": [
    "### <font color = darkblue>${\\textbf{2. Stacking multiple classifiers and a pipeline on a metamodel in addition to Grid Search}}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f61f00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some classifiers and a pipeline\n",
    "clf1 = RandomForestClassifier()\n",
    "\n",
    "clf2 = Pipeline([('pca', PCA(n_components = 'mle', svd_solver = 'full')), \n",
    "                 ('minmax', MinMaxScaler()),\n",
    "                 ('clf', mnb)])\n",
    "\n",
    "clf3 = xgb.XGBClassifier(learning_rate=0.1)\n",
    "\n",
    "# LR\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8e39ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking the classifiers\n",
    "sclf = StackingClassifier(classifiers = [clf1, clf2, clf3], \n",
    "                          meta_classifier = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4f5480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=StackingClassifier(classifiers=[RandomForestClassifier(),\n",
       "                                                       Pipeline(steps=[('pca',\n",
       "                                                                        PCA(n_components='mle',\n",
       "                                                                            svd_solver='full')),\n",
       "                                                                       ('minmax',\n",
       "                                                                        MinMaxScaler()),\n",
       "                                                                       ('clf',\n",
       "                                                                        MultinomialNB())]),\n",
       "                                                       XGBClassifier(base_score=None,\n",
       "                                                                     booster=None,\n",
       "                                                                     callbacks=None,\n",
       "                                                                     colsample_bylevel=None,\n",
       "                                                                     colsample_bynode=None,\n",
       "                                                                     colsample_bytree=None,\n",
       "                                                                     early_stopping_rounds=None,...\n",
       "                                                                     max_delta_step=None,\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_leaves=None,\n",
       "                                                                     min_child_weight=None,\n",
       "                                                                     missing=nan,\n",
       "                                                                     monotone_constraints=None,\n",
       "                                                                     n_estimators=100,\n",
       "                                                                     n_jobs=None,\n",
       "                                                                     num_parallel_tree=None,\n",
       "                                                                     predictor=None,\n",
       "                                                                     random_state=None,\n",
       "                                                                     reg_alpha=None,\n",
       "                                                                     reg_lambda=None, ...)],\n",
       "                                          meta_classifier=LogisticRegression()),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'randomforestclassifier__n_estimators': [10, 25, 40,\n",
       "                                                                  50]},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search parameters\n",
    "params = {'randomforestclassifier__n_estimators': [10, 25, 40, 50]}\n",
    "# Declare GridSearchCV\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    verbose = 4,\n",
    "                    n_jobs = -1,\n",
    "                    refit=True)\n",
    "# Fir GS\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb5b6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.523 +/- 0.00 {'randomforestclassifier__n_estimators': 10}\n",
      "0.517 +/- 0.01 {'randomforestclassifier__n_estimators': 25}\n",
      "0.524 +/- 0.00 {'randomforestclassifier__n_estimators': 40}\n",
      "0.522 +/- 0.00 {'randomforestclassifier__n_estimators': 50}\n",
      "Best parameters: {'randomforestclassifier__n_estimators': 40}\n",
      "Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "    \n",
    "    \n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bfc1d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score for best params: 0.538 \n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "# Test data accuracy of model with best params\n",
    "print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "# Track best (highest test accuracy) model\n",
    "if accuracy_score(y_test, y_pred) > best_acc:\n",
    "    best_acc = accuracy_score(y_test, y_pred)\n",
    "    best_gs = gs\n",
    "    best_clf = idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
